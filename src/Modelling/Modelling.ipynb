{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modelling",
   "id": "870f0292883ca80a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading & Libraries",
   "id": "4bc05b0294bed600"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:50.984008Z",
     "start_time": "2025-09-12T03:03:48.565784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json, pandas as pd, numpy as np, random\n",
    "from typing import Dict, List, Any\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import sparse\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# KNN + SVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from explanations import attach_llm_explanations\n",
    "\n",
    "ART = Path('../../data/processed')\n",
    "\n",
    "W_NOTE = {\"top\": 0.35, \"mid\": 0.40, \"base\": 0.25}\n",
    "\n",
    "W_BLOCK = {\"accord\": 0.80, \"meta\": 0.20}\n",
    "\n",
    "ACCORD_POS_WEIGHTS = np.array([1.0, 0.8, 0.6, 0.4, 0.2], dtype=np.float32)\n",
    "DEFAULT_ACCORD_WEIGHT = 0.6\n",
    "\n",
    "SEASON_TO_ACCORD_HINTS = {\n",
    "    \"summer\": {\n",
    "        \"boost\": {\n",
    "            \"citrus\", \"aquatic\", \"ozonic\", \"green\", \"aromatic\", \"fresh\", \"fresh spicy\",\n",
    "            \"fruity\", \"marine\", \"soapy\", \"tropical\", \"salty\", \"coconut\", \"musky\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"amber\", \"sweet\", \"gourmand\", \"smoky\", \"leather\", \"tobacco\", \"vanilla\", \"balsamic\",\n",
    "            \"oud\", \"chocolate\", \"honey\", \"coffee\", \"oriental\"\n",
    "        },\n",
    "    },\n",
    "    \"spring\": {\n",
    "        \"boost\": {\n",
    "            \"floral\", \"white floral\", \"green\", \"citrus\", \"aromatic\", \"fresh\", \"fresh spicy\",\n",
    "            \"violet\", \"rose\", \"herbal\", \"aldehydic\", \"powdery\", \"lavender\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"animalic\", \"leather\", \"oud\", \"smoky\", \"tobacco\", \"gourmand\"\n",
    "        },\n",
    "    },\n",
    "    \"fall\": {\n",
    "        \"boost\": {\n",
    "            \"woody\", \"warm spicy\", \"amber\", \"tobacco\", \"leather\", \"balsamic\",\n",
    "            \"patchouli\", \"vanilla\", \"cinnamon\", \"honey\", \"earthy\", \"mossy\",\n",
    "            \"oriental\", \"coffee\", \"chocolate\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"aquatic\", \"ozonic\", \"marine\", \"soapy\", \"fresh\"\n",
    "        },\n",
    "    },\n",
    "    \"winter\": {\n",
    "        \"boost\": {\n",
    "            \"amber\", \"vanilla\", \"sweet\", \"smoky\", \"leather\", \"balsamic\", \"oud\", \"tobacco\",\n",
    "            \"whiskey\", \"rum\", \"wine\", \"chocolate\", \"cacao\", \"coffee\",\n",
    "            \"spicy\", \"warm spicy\", \"oriental\", \"honey\", \"almond\", \"nutty\", \"powdery\", \"musky\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"aquatic\", \"green\", \"ozonic\", \"citrus\", \"fresh\", \"marine\", \"tropical\", \"coconut\"\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "USE_CASE_HINTS = {\n",
    "    \"office\": {\n",
    "        \"boost\": {\n",
    "            \"citrus\", \"aromatic\", \"green\", \"woody\", \"fresh spicy\", \"musky\", \"powdery\", \"soapy\", \"ozonic\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"animalic\", \"oud\", \"smoky\", \"leather\", \"gourmand\", \"sweet\", \"tobacco\",\n",
    "            \"alcohol\", \"rum\", \"whiskey\", \"wine\", \"vodka\", \"champagne\",\n",
    "            \"coffee\", \"chocolate\", \"honey\", \"cannabis\"\n",
    "        },\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"boost\": {\n",
    "            \"vanilla\", \"amber\", \"sweet\", \"fruity\", \"warm spicy\", \"soft spicy\",\n",
    "            \"white floral\", \"rose\", \"musky\", \"powdery\",\n",
    "            \"chocolate\", \"honey\", \"coconut\", \"tropical\", \"almond\", \"caramel\", \"lactonic\", \"creamy\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"aquatic\", \"ozonic\", \"green\", \"aldehydic\", \"soapy\", \"metallic\", \"marine\", \"fresh\"\n",
    "        },\n",
    "    },\n",
    "    \"gym\": {\n",
    "        \"boost\": {\n",
    "            \"citrus\", \"green\", \"aquatic\", \"ozonic\", \"aromatic\", \"fresh\", \"fresh spicy\",\n",
    "            \"soapy\", \"musky\", \"marine\", \"herbal\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"sweet\", \"gourmand\", \"amber\", \"vanilla\", \"oud\", \"smoky\", \"leather\", \"tobacco\",\n",
    "            \"honey\", \"chocolate\", \"coffee\", \"coconut\", \"oriental\", \"balsamic\"\n",
    "        },\n",
    "    },\n",
    "    \"casual\": {\n",
    "        \"boost\": {\n",
    "            \"citrus\", \"fruity\", \"aromatic\", \"green\", \"aquatic\", \"fresh\", \"fresh spicy\",\n",
    "            \"musky\", \"woody\", \"soapy\", \"ozonic\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"animalic\", \"oud\", \"leather\", \"tobacco\", \"smoky\", \"gourmand\", \"sweet\", \"coffee\", \"cannabis\"\n",
    "        },\n",
    "    },\n",
    "    \"formal\": {\n",
    "        \"boost\": {\n",
    "            \"woody\", \"iris\", \"aldehydic\", \"amber\", \"leather\", \"powdery\", \"rose\",\n",
    "            \"spicy\", \"soft spicy\", \"warm spicy\", \"patchouli\", \"musky\", \"balsamic\", \"violet\", \"oriental\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"gourmand\", \"sweet\", \"aquatic\", \"ozonic\", \"fruity\", \"tropical\", \"coconut\", \"cherry\"\n",
    "        },\n",
    "    },\n",
    "    \"signature\": {\n",
    "        \"boost\": {\n",
    "            \"citrus\", \"aromatic\", \"woody\", \"green\", \"fresh spicy\", \"musky\", \"powdery\", \"soapy\",\n",
    "            \"floral\", \"white floral\", \"ozonic\"\n",
    "        },\n",
    "        \"penalize\": {\n",
    "            \"animalic\", \"oud\", \"smoky\", \"tobacco\", \"gourmand\", \"sweet\", \"leather\",\n",
    "            \"coffee\", \"cannabis\", \"oriental\"\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "INTENSITY_WEIGHT = {\"soft\": -0.10, \"moderate\": 0.0, \"loud\": +0.10}\n",
    "\n",
    "CFG = {\n",
    "    #Seed\n",
    "    'seed': 42,\n",
    "    # embeddings\n",
    "    \"embed_dim\": 256,          # try 128/256/384 if needed\n",
    "\n",
    "    # retrieval\n",
    "    \"knn_neighbors\": 1000,      # recall pool size before MMR\n",
    "    \"mmr_lambda\": 0.40,         # 0.6 relevance / 0.4 diversity\n",
    "    \"topk\": 20,                # final list length\n",
    "\n",
    "    # AE training\n",
    "    \"ae_epochs\": 10,\n",
    "    \"ae_batch\": 256,\n",
    "    \"ae_lr\": 1e-3,\n",
    "    \"ae_p_mask\": 0.15,         # denoising: randomly drop inputs\n",
    "\n",
    "    # evaluation\n",
    "    \"eval_k\": 20               # evaluate top-k lists\n",
    "}"
   ],
   "id": "f7da2ed6bfd1f954",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:51.131724Z",
     "start_time": "2025-09-12T03:03:50.987821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set seed for reproducibility\n",
    "random.seed(CFG['seed']); np.random.seed(CFG['seed']); torch.manual_seed(CFG['seed'])\n",
    "\n",
    "# load data\n",
    "X = sparse.load_npz(ART/'X_sparse.npz').tocsr()\n",
    "personas = pd.read_parquet(ART/'personas_v3.parquet')\n",
    "feature_meta = json.loads((ART/'feature_meta.json').read_text())\n",
    "items = pd.read_parquet(ART/'items.parquet')\n",
    "bridge  = pd.read_parquet(ART/'fragrance_note_bridge.parquet')\n",
    "\n",
    "feat_names = feature_meta['feature_names']\n",
    "feat_pos = {c:i for i,c in enumerate(feat_names)}"
   ],
   "id": "5178db6cac749cf1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:51.140860Z",
     "start_time": "2025-09-12T03:03:51.137411Z"
    }
   },
   "cell_type": "code",
   "source": "personas['liked_accords_ranked'][0]",
   "id": "6ccfc5b0c7edcd56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'name': 'woody', 'rank': 1}, {'name': 'warm spicy', 'rank': 2},\n",
       "       {'name': 'amber', 'rank': 3}, {'name': 'leather', 'rank': 4},\n",
       "       {'name': 'smoky', 'rank': 5}], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Utility Functions (L2 , MMR)",
   "id": "333280be3ccd09e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since the Sparse Matrix and the queries are l2 normalized, the cosine similarity turns into a dot product.",
   "id": "5aadefcaf8d29068"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:51.153588Z",
     "start_time": "2025-09-12T03:03:51.150479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this function l2 normalizes a row in a csr matrix\n",
    "def l2_normalize_row(q: sparse.csr_matrix) -> sparse.csr_matrix:\n",
    "    n = np.sqrt(q.multiply(q).sum())\n",
    "    return q if n == 0 else q.multiply(1.0/float(n))\n",
    "\n",
    "def mmr_from_relevance(rel_scores: np.ndarray,\n",
    "                       cand_vecs: np.ndarray,\n",
    "                       cand_ids: np.ndarray,\n",
    "                       lambda_relevance: float = CFG[\"mmr_lambda\"],\n",
    "                       top_k: int = CFG[\"topk\"]) -> list:\n",
    "    \"\"\"\n",
    "    MMR using precomputed relevance scores for each candidate (rel_scores ~ length m),\n",
    "    and candidate embeddings for diversity (cand_vecs ~ (m×d), L2-normalized rows).\n",
    "    \"\"\"\n",
    "    rel = np.asarray(rel_scores).ravel()\n",
    "    m = len(cand_ids)\n",
    "    assert rel.shape[0] == m and cand_vecs.shape[0] == m, \"rel_scores and cand_vecs must align\"\n",
    "\n",
    "    selected, rest = [], list(range(m))\n",
    "    for _ in range(min(top_k, m)):\n",
    "        if not selected:\n",
    "            j = int(np.argmax(rel[rest]))\n",
    "            selected.append(rest.pop(j))\n",
    "            continue\n",
    "\n",
    "        # max similarity to the already selected set (diversity term)\n",
    "        S = cand_vecs[selected] @ cand_vecs[rest].T          # (|S| × |rest|)\n",
    "        max_sim = S.max(axis=0)                              # (|rest|,)\n",
    "\n",
    "        # MMR score = λ·relevance − (1−λ)·redundancy\n",
    "        score = lambda_relevance * rel[rest] - (1.0 - lambda_relevance) * max_sim\n",
    "        j = int(np.argmax(score))\n",
    "        selected.append(rest.pop(j))\n",
    "\n",
    "    return [cand_ids[i] for i in selected]"
   ],
   "id": "60b9fd1e448a140",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipeline A: SVD -> KNN -> MMR",
   "id": "2dfb02cc0eddded2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:52.699213Z",
     "start_time": "2025-09-12T03:03:51.173770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "svd = TruncatedSVD(n_components=CFG['embed_dim'],random_state=42)\n",
    "svd_pipe = make_pipeline(svd, Normalizer(copy=False))\n",
    "Z_svd = svd_pipe.fit_transform(X)\n",
    "\n",
    "knn_svd = NearestNeighbors(n_neighbors=CFG['knn_neighbors'], metric='cosine').fit(Z_svd)\n",
    "\n",
    "np.save(ART/'svd_embeddings.npy', Z_svd.astype('float32'))\n",
    "dump(svd_pipe, ART/'svd_pipe.joblib')\n",
    "dump(knn_svd, ART/'svd_knn.joblib')"
   ],
   "id": "2a476634ad6db3e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/processed/svd_knn.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We normalize after SVD to keep the direction our focus instead of magnitudes as component magnitudes will skew similarities in kNN search. Normalizing insures that you get more diverse neighbors, basically unclustering by size of embeddings, so just direction matters.",
   "id": "9b2fc63cd34670be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pipeline B: Masked Autoencoder -> KNN -> MMR",
   "id": "900d06d365c2fc3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:03:52.808787Z",
     "start_time": "2025-09-12T03:03:52.793508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CSRDataset(Dataset):\n",
    "    def __init__(self, X : sparse.csr_matrix, p_mask=0.15, to_tensor: bool = True):\n",
    "        self.X, self.p_mask, self.D, self.to_tensor = X, p_mask, X.shape[1], to_tensor\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i):\n",
    "        row = self.X.getrow(i).toarray().astype(np.float32).ravel()\n",
    "        if self.p_mask>0:\n",
    "            m = (np.random.rand(self.D) < self.p_mask)\n",
    "            x = row.copy()\n",
    "            x[m] = 0.0\n",
    "        else:\n",
    "            x = row\n",
    "\n",
    "        if self.to_tensor:\n",
    "            x = torch.from_numpy(x)\n",
    "            row = torch.from_numpy(row)\n",
    "        return x, row\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, D, d=256):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(nn.Linear(D, 1024), nn.ReLU(), nn.Linear(1024, d))\n",
    "        self.dec = nn.Sequential(nn.Linear(d,1024), nn.ReLU(), nn.Linear(1024, D))\n",
    "    def forward(self,x):\n",
    "        z = self.enc(x)\n",
    "        return z, self.dec(z)"
   ],
   "id": "40f3513ab4ff28be",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We will use a Masked Autoencoder (MAE) to make the model more robust at handling incomplete data, as well as generalize better and avoid overfitting.",
   "id": "458fc9356cdf714b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:15.659424Z",
     "start_time": "2025-09-12T03:03:52.815383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "ds = CSRDataset(X, p_mask=CFG['ae_p_mask'], to_tensor=True)\n",
    "dl = DataLoader(ds, batch_size=CFG['ae_batch'],shuffle= True, num_workers=0)\n",
    "\n",
    "model = Autoencoder(D=X.shape[1],d=CFG['embed_dim']).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(),lr = CFG['ae_lr'])\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, CFG['ae_epochs']+1):\n",
    "    tot = 0.0\n",
    "    for xb, yb in dl:\n",
    "        xb, yb  = xb.to(device, non_blocking=True).float(), yb.to(device,non_blocking=True).float()\n",
    "        z, xhat = model(xb)\n",
    "        loss = loss_fn(xhat, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        tot += loss.item()*xb.size(0)\n",
    "    print(f\"epoch {epoch:02d}: {tot/len(dl.dataset):.6f}\")"
   ],
   "id": "9bf797ba40511946",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01: 0.000392\n",
      "epoch 02: 0.000266\n",
      "epoch 03: 0.000217\n",
      "epoch 04: 0.000194\n",
      "epoch 05: 0.000179\n",
      "epoch 06: 0.000168\n",
      "epoch 07: 0.000160\n",
      "epoch 08: 0.000153\n",
      "epoch 09: 0.000148\n",
      "epoch 10: 0.000144\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.614605Z",
     "start_time": "2025-09-12T03:04:15.776782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def batch_encode_csr(model, X_csr, batch_size=CFG['ae_batch'], device = device):\n",
    "    model.eval()\n",
    "    emb=[]\n",
    "\n",
    "    loader = DataLoader(CSRDataset(X_csr, p_mask=0.0, to_tensor=True),\n",
    "                        batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    for xb, _ in loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        z, _ = model(xb)\n",
    "        z = z / (z.norm(dim=1,keepdim=True) + 1e-9)\n",
    "        emb.append(z.cpu().numpy())\n",
    "\n",
    "    return np.vstack(emb).astype('float32')\n",
    "\n",
    "Z_ae = batch_encode_csr(model, X, batch_size=CFG['ae_batch'], device=device)\n",
    "knn_ae = NearestNeighbors(n_neighbors=CFG['knn_neighbors'], metric='cosine').fit(Z_ae)"
   ],
   "id": "1d16059b026636f1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.774356Z",
     "start_time": "2025-09-12T03:04:16.678477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), ART/'ae.pt')\n",
    "np.save(ART/'ae_embeddings.npy', Z_ae)\n",
    "dump(knn_ae, ART/'ae_knn.joblib')"
   ],
   "id": "c4697404cbf11920",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/processed/ae_knn.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query Building from User/Persona",
   "id": "3ad266b25cab4624"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.785144Z",
     "start_time": "2025-09-12T03:04:16.778536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "note_to_col = {\n",
    "    \"top\":  {n: f\"{n}_top\"  for n in feature_meta[\"top_mlb_classes\"]},\n",
    "    \"mid\":  {n: f\"{n}_mid\"  for n in feature_meta[\"mid_mlb_classes\"]},\n",
    "    \"base\": {n: f\"{n}_base\" for n in feature_meta[\"base_mlb_classes\"]},\n",
    "}\n",
    "\n",
    "def _rank_weight(rank: int) -> float:\n",
    "    return float(ACCORD_POS_WEIGHTS[rank-1]) if 1 <= rank <= 5 else 0.0\n",
    "\n",
    "def build_query(pref: dict) -> sparse.csr_matrix:\n",
    "    \"\"\"\n",
    "    Returns a (1×D) CSR row in the **same feature space and order** as X_sparse.\n",
    "    Blocks & weights mirror training:\n",
    "      - Notes: per-level weight (top/mid/base) + per-block L2\n",
    "      - Avoid notes: same as liked but NEGATIVE weight\n",
    "      - Accords: rank weights [1,.8,.6,.4,.2] + per-block L2, then × W_BLOCK[\"accord\"]\n",
    "      - Disliked accords: NEGATIVE default weight (no rank) in accord block\n",
    "      - Meta: neutral (zeros unless provided separately)\n",
    "    \"\"\"\n",
    "    D = len(feat_names)\n",
    "\n",
    "    # ----- Notes block (liked + avoid) -----\n",
    "    cols_notes, data_notes = [], []\n",
    "\n",
    "    def add_note(level: str, name: str, weight: float):\n",
    "        name = str(name).strip().lower()\n",
    "        col_name = note_to_col[level].get(name)\n",
    "        if col_name is None:\n",
    "            return\n",
    "        j = feat_pos.get(col_name)\n",
    "        if j is None:\n",
    "            return\n",
    "        cols_notes.append(j)\n",
    "        data_notes.append(weight)\n",
    "\n",
    "    # liked notes (positive weights)\n",
    "    for level_key, level in [\n",
    "        (\"liked_notes_top\",  \"top\"),\n",
    "        (\"liked_notes_mid\",  \"mid\"),\n",
    "        (\"liked_notes_base\", \"base\"),\n",
    "    ]:\n",
    "        for n in map(str, pref.get(level_key, [])):\n",
    "            add_note(level, n, W_NOTE[level])\n",
    "\n",
    "    # avoid notes (negative weights)\n",
    "    for n in map(str, pref.get(\"avoid_notes\", [])):\n",
    "        # check all three levels (avoid could be in any vocab)\n",
    "        for level in (\"top\", \"mid\", \"base\"):\n",
    "            if n in note_to_col[level]:\n",
    "                add_note(level, n, -W_NOTE[level])\n",
    "\n",
    "    notes_row = sparse.csr_matrix(\n",
    "        (data_notes, ([0]*len(cols_notes), cols_notes)),\n",
    "        shape=(1, D), dtype=np.float32\n",
    "    )\n",
    "    notes_row = l2_normalize_row(notes_row)\n",
    "\n",
    "    # ----- Accords block (liked + disliked) -----\n",
    "    cols_acc, data_acc = [], []\n",
    "    used_ranks = set()\n",
    "    for entry in pref.get(\"liked_accords_ranked\", []):\n",
    "        name = str(entry.get(\"name\", \"\")).strip().lower()\n",
    "        rank = int(entry.get(\"rank\", 0))\n",
    "        if not (1 <= rank <= 5):\n",
    "            continue\n",
    "        if rank in used_ranks:\n",
    "            continue\n",
    "        j = feat_pos.get(f\"accord_{name}\")\n",
    "        if j is None:\n",
    "            continue\n",
    "        cols_acc.append(j)\n",
    "        data_acc.append(_rank_weight(rank))\n",
    "        used_ranks.add(rank)\n",
    "\n",
    "    # disliked accords (negative default weight)\n",
    "    for name in map(str, pref.get(\"disliked_accords\", [])):\n",
    "        j = feat_pos.get(f\"accord_{name.strip().lower()}\")\n",
    "        if j is None:\n",
    "            continue\n",
    "        cols_acc.append(j)\n",
    "        data_acc.append(-DEFAULT_ACCORD_WEIGHT)\n",
    "\n",
    "    acc_row = sparse.csr_matrix(\n",
    "        (data_acc, ([0]*len(cols_acc), cols_acc)),\n",
    "        shape=(1, D), dtype=np.float32\n",
    "    )\n",
    "    acc_row = l2_normalize_row(acc_row).multiply(W_BLOCK[\"accord\"])\n",
    "\n",
    "    meta_row = sparse.csr_matrix((1, D), dtype=np.float32)\n",
    "\n",
    "    q = notes_row + acc_row + meta_row\n",
    "    return q.tocsr()"
   ],
   "id": "b34c03f2724aa672",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert all personas to queries",
   "id": "bdae45f87fc1e2d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.825629Z",
     "start_time": "2025-09-12T03:04:16.790739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def personas_to_csr_from_df(df: pd.DataFrame, feature_meta: dict) -> sparse.csr_matrix:\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        # Reuse your build_query directly; we only encode taste (notes/accords).\n",
    "        pref = {\n",
    "            \"liked_accords_ranked\": r[\"liked_accords_ranked\"],\n",
    "            \"disliked_accords\": r['disliked_accords'],\n",
    "            \"liked_notes_top\": r[\"liked_notes_top\"],\n",
    "            \"liked_notes_mid\": r[\"liked_notes_mid\"],\n",
    "            \"liked_notes_base\": r[\"liked_notes_base\"],\n",
    "            \"avoid_notes\": r['avoid_notes'],\n",
    "            'gender_focus': r['gender_focus'],\n",
    "            'season' : r['season'],\n",
    "            'use_case' : r['use_case'],\n",
    "            'intensity': r['intensity']\n",
    "        }\n",
    "        q = build_query(pref)   # (1×D) CSR in the same feature space as X_sparse\n",
    "        rows.append(q)\n",
    "    return sparse.vstack(rows).tocsr()\n",
    "\n",
    "P_csr = personas_to_csr_from_df(personas, feature_meta)\n",
    "sparse.save_npz(ART/'personas_csr.npz',P_csr)\n",
    "print(\"Personas CSR shape:\", P_csr.shape)"
   ],
   "id": "46ca7b3d4afe2f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas CSR shape: (92, 3476)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Query Encodings for Both Pipelines",
   "id": "64504eb42aa36090"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.845641Z",
     "start_time": "2025-09-12T03:04:16.828748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ZP_ae = batch_encode_csr(model, P_csr, batch_size=CFG['ae_batch'], device=device)\n",
    "ZP_svd = svd_pipe.transform(P_csr).astype('float32')\n",
    "\n",
    "# Save\n",
    "np.save(ART/'persona_ae_embeddings.npy', ZP_ae)\n",
    "np.save(ART/'persona_svd_embeddings.npy', ZP_svd)"
   ],
   "id": "47390f8fa91257dc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Persona + Fragrance Affinity",
   "id": "7bbc40951bf011c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.890144Z",
     "start_time": "2025-09-12T03:04:16.848844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A_item_persona_ae  = Z_ae  @ ZP_ae.T   # (N_items × P)\n",
    "A_item_persona_svd = Z_svd @ ZP_svd.T\n",
    "\n",
    "# Save\n",
    "np.save(ART/'A_item_persona_ae.npy',  A_item_persona_ae.astype('float32'))\n",
    "np.save(ART/'A_item_persona_svd.npy', A_item_persona_svd.astype('float32'))"
   ],
   "id": "453236436025bb04",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recomendation Engine",
   "id": "a8fed67af7b3ec7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encoding Functions for Preferences",
   "id": "9988ae6b9943bc20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.904475Z",
     "start_time": "2025-09-12T03:04:16.897998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_query_ae(preference: dict, model, device: str = device) -> np.ndarray:\n",
    "    q = build_query(preference)  # (1×D) CSR aligned to X_sparse\n",
    "    with torch.no_grad():\n",
    "        xb = torch.from_numpy(q.toarray().astype(np.float32)).to(device)\n",
    "        z, _ = model(xb)\n",
    "        z = z / (z.norm(dim=1, keepdim=True) + 1e-9)\n",
    "    return z.cpu().numpy()  # (1×d)\n",
    "\n",
    "def encode_query_svd(preference: dict, svd_pipe) -> np.ndarray:\n",
    "    q = build_query(preference)  # (1×D) CSR\n",
    "    z = svd_pipe.transform(q)\n",
    "    return z.astype('float32')  # (1×d)"
   ],
   "id": "2e16a1cc466224a9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Persona Boost: Blend content relevance with a collaborative persona signal.",
   "id": "26dde7410e044944"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This makes sure that our recommender gets the collaborative signal from other people and adds the 'others liked this, so you might as well' part to the recommendations. As well as adding context bias such as filters for Season and Use Cases by boosting/penalizing certain accords.",
   "id": "9e578b91441d0ff0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.930805Z",
     "start_time": "2025-09-12T03:04:16.913350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def persona_boost(zq_vec: np.ndarray,\n",
    "                  Z_persona: np.ndarray,\n",
    "                  A_item_persona: np.ndarray,\n",
    "                  cand_ids: np.ndarray,\n",
    "                  top_personas: int = 12,\n",
    "                  temperature: float = 0.1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute a collaborative 'people-like-you' score for candidate items using precomputed item-to-persona affinities.\n",
    "    \"\"\"\n",
    "    #similiarity of query to each persona\n",
    "    sim_p = Z_persona @ zq_vec\n",
    "\n",
    "    # focus on top persona matches; suppress noise from weakly similar personas\n",
    "    if top_personas and top_personas < sim_p.size:\n",
    "        keep = np.argpartition(-sim_p,top_personas)[:top_personas]\n",
    "        mask = np.full_like(sim_p, -np.inf, dtype=np.float32)\n",
    "        mask[keep] = sim_p[keep]\n",
    "        sim_p=mask\n",
    "\n",
    "    # softmax weights over personas\n",
    "    x = sim_p / max(1e-6, float(temperature))\n",
    "    x = x - np.nanmax(x[np.isfinite(x)])\n",
    "    w = np.exp(np.where(np.isfinite(x), x, -1e9))\n",
    "    w = w / (w.sum() + 1e-9)  # (P,)\n",
    "\n",
    "    # persona boost for the specific candidates: (m×P) @ (P,) → (m,)\n",
    "    boost = A_item_persona[cand_ids] @ w\n",
    "\n",
    "    # scale to 0..1 for stable blending\n",
    "    bmin, bmax = boost.min(), boost.max()\n",
    "    return ((boost - bmin) / (bmax - bmin + 1e-9)).astype('float32')\n",
    "\n",
    "def inject_context_bias(rel_vec: np.ndarray, cand_ids: np.ndarray, items_df: pd.DataFrame,\n",
    "                        preference: dict, bonus=0.01, penalty=0.01) -> np.ndarray:\n",
    "    \"\"\"Light, optional pre-MMR nudge using season/use_case hints.\"\"\"\n",
    "    season   = (preference.get(\"season\") or \"\").strip().lower()\n",
    "    use_case = (preference.get(\"use_case\") or \"\").strip().lower()\n",
    "\n",
    "    rel = rel_vec.copy()\n",
    "    for i, idx in enumerate(cand_ids):\n",
    "        accs = accords_set_from_row(items_df.iloc[idx])\n",
    "        if season in SEASON_TO_ACCORD_HINTS:\n",
    "            b = SEASON_TO_ACCORD_HINTS[season][\"boost\"]; p = SEASON_TO_ACCORD_HINTS[season][\"penalize\"]\n",
    "            if accs & b: rel[i] += bonus\n",
    "            if accs & p: rel[i] -= penalty\n",
    "        if use_case in USE_CASE_HINTS:\n",
    "            b = USE_CASE_HINTS[use_case][\"boost\"]; p = USE_CASE_HINTS[use_case][\"penalize\"]\n",
    "            if accs & b: rel[i] += bonus\n",
    "            if accs & p: rel[i] -= penalty\n",
    "    return rel"
   ],
   "id": "e292a03390ea132f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recommendation Helpers",
   "id": "229f4b4d431d11ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.955159Z",
     "start_time": "2025-09-12T03:04:16.941422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gender_ok(row_gender: str, pref: str) -> bool:\n",
    "    g = (row_gender or \"\").strip().lower()\n",
    "    p = (pref or \"\").strip().lower()\n",
    "    if not p: return True\n",
    "    if p == \"unisex\":         return g in {\"unisex\"}\n",
    "    if p == \"men\":            return g in {\"men\",\"unisex\"}\n",
    "    if p == \"women\":          return g in {\"women\",\"unisex\"}\n",
    "    # if user is strict, you could enforce equality only:\n",
    "    return g == p\n",
    "\n",
    "def get_item_notes(fragrance_id: str, bridge_df: pd.DataFrame, k_per_level=4) -> dict:\n",
    "    if bridge_df is None: return {}\n",
    "    sub = bridge_df[bridge_df['fragrance_id'] == fragrance_id]\n",
    "    out = {}\n",
    "    for level in ('top','mid','base'):\n",
    "        notes = sub.loc[sub['level'] == level,'note'].tolist()\n",
    "        out[level] = notes[:k_per_level]\n",
    "    return out\n",
    "\n",
    "def accords_set_from_row(row: pd.Series) -> set:\n",
    "    acc = []\n",
    "    for k in (\"mainaccord1\",\"mainaccord2\",\"mainaccord3\",\"mainaccord4\",\"mainaccord5\"):\n",
    "        v = row.get(k, None)\n",
    "        if pd.isna(v):\n",
    "            continue\n",
    "        s = str(v).strip().lower()\n",
    "        if s and s != \"nan\":\n",
    "            acc.append(s)\n",
    "    return set(acc)\n",
    "\n",
    "def prefilter_candidates(cand_ids: np.ndarray, items_df: pd.DataFrame, preference: Dict[str, Any]) -> List[int]:\n",
    "    gender_pref = (preference.get(\"gender_focus\") or \"\").strip().lower()\n",
    "    keep = []\n",
    "    for idx in cand_ids:\n",
    "        row = items_df.iloc[idx]\n",
    "        if gender_pref and not gender_ok(str(row.get(\"Gender\",\"\")), gender_pref):\n",
    "            continue\n",
    "        keep.append(idx)\n",
    "    return keep if keep else list(cand_ids)\n",
    "\n",
    "def soft_context_rerank(selected_ids: List[int], items_df: pd.DataFrame, preference: Dict[str, Any]) -> List[int]:\n",
    "    season   = (preference.get(\"season\") or \"\").strip().lower()\n",
    "    use_case = (preference.get(\"use_case\") or \"\").strip().lower()\n",
    "    intensity= (preference.get(\"intensity\") or \"\").strip().lower()\n",
    "\n",
    "    scores = np.zeros(len(selected_ids), dtype=np.float32)\n",
    "    for i, idx in enumerate(selected_ids):\n",
    "        row = items_df.iloc[idx]\n",
    "        accs = accords_set_from_row(row)\n",
    "\n",
    "        if season in SEASON_TO_ACCORD_HINTS:\n",
    "            b = SEASON_TO_ACCORD_HINTS[season][\"boost\"]\n",
    "            p = SEASON_TO_ACCORD_HINTS[season][\"penalize\"]\n",
    "            if accs & b: scores[i] += 0.05\n",
    "            if accs & p: scores[i] -= 0.05\n",
    "\n",
    "        if use_case in USE_CASE_HINTS:\n",
    "            b = USE_CASE_HINTS[use_case][\"boost\"]\n",
    "            p = USE_CASE_HINTS[use_case][\"penalize\"]\n",
    "            if accs & b: scores[i] += 0.05\n",
    "            if accs & p: scores[i] -= 0.05\n",
    "\n",
    "        if intensity in INTENSITY_WEIGHT:\n",
    "            scores[i] += INTENSITY_WEIGHT[intensity]\n",
    "\n",
    "    order = np.argsort(-scores, kind=\"stable\")\n",
    "    return [selected_ids[j] for j in order]"
   ],
   "id": "782f98a0e4ba8daf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recommender",
   "id": "2f30730dd9fe05c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:04:16.973334Z",
     "start_time": "2025-09-12T03:04:16.961698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend(preference: dict,\n",
    "              mode: str = 'ae',\n",
    "              top_k: int = CFG['topk'],\n",
    "              beta_persona: float = 0.35,\n",
    "              mmr_lambda: float = CFG['mmr_lambda'],\n",
    "              top_personas: int = 20,\n",
    "              temperature: float = 0.2,\n",
    "              use_context_bias: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    preference: dict with liked_accords_ranked, liked_notes_top/mid/base, and optional filters:\n",
    "      gender_focus ∈ {\"men\",\"women\",\"unisex\",\"any\"}, season, use_case, intensity\n",
    "    \"\"\"\n",
    "    # 1) encode query\n",
    "    if mode == 'ae':\n",
    "        zq = encode_query_ae(preference,model,device)\n",
    "        Z_catalog, knn_index = Z_ae, knn_ae\n",
    "        Z_persona = ZP_ae; A_item_persona = A_item_persona_ae\n",
    "    else:\n",
    "        zq = encode_query_svd(preference,svd_pipe)\n",
    "        Z_catalog, knn_index = Z_svd, knn_svd\n",
    "        Z_persona = ZP_svd; A_item_persona = A_item_persona_svd\n",
    "\n",
    "    zqv = zq.ravel()\n",
    "\n",
    "    # 2) Get large candidate pool, hard prefilter(gender)\n",
    "    _, nbrs = knn_index.kneighbors(zq,n_neighbors=CFG['knn_neighbors'])\n",
    "    cand_ids = nbrs[0]\n",
    "    cand_ids = np.array(prefilter_candidates(cand_ids,items,preference),dtype=int)\n",
    "    if cand_ids.size == 0:\n",
    "        return items.iloc[:0].copy()\n",
    "\n",
    "    # 3) Compute relevance signals\n",
    "    Z_cand = Z_catalog[cand_ids]\n",
    "    rel_content = Z_cand @ zqv\n",
    "    rel_persona = persona_boost(zqv, Z_persona,A_item_persona,cand_ids, top_personas, temperature)\n",
    "    rel_fused = (1.0 - beta_persona) * rel_content + beta_persona * rel_persona\n",
    "\n",
    "    # optional to add context bias\n",
    "    if use_context_bias:\n",
    "        rel_fused = inject_context_bias(rel_fused,cand_ids,items,preference,bonus=0.02,penalty=0.02)\n",
    "\n",
    "    # 4) Diversify with MMR\n",
    "    selected = mmr_from_relevance(rel_fused,Z_cand, cand_ids,lambda_relevance=mmr_lambda, top_k=top_k)\n",
    "\n",
    "    # 5) Soft rerank (season/use_case/intensity)\n",
    "    selected = soft_context_rerank(selected,items,preference)\n",
    "\n",
    "    # 6) results + explanations\n",
    "    pos = {cid:i for i,cid in enumerate(cand_ids)}\n",
    "    cols = [\"fragrance_id\",\"Brand\",\"Perfume\",\"Year\",\"Gender\",\n",
    "            \"mainaccord1\",\"mainaccord2\",\"mainaccord3\",\"mainaccord4\",\"mainaccord5\",\n",
    "            \"Weighted Rating\",\"Rating Count\",\"url\"]\n",
    "    df = items.iloc[selected][cols].copy()\n",
    "\n",
    "    df['score_content'] = [float(rel_content[pos[i]]) for i in selected]\n",
    "    df['score_persona'] = [float(rel_persona[pos[i]]) for i in selected]\n",
    "    df['score_fused'] = [float(rel_fused[pos[i]]) for i in selected]\n",
    "\n",
    "    # explainability\n",
    "    query_accords = {str(a.get('name','')).strip().lower() for a in (preference.get('liked_accords_ranked')) if isinstance(a,dict)}\n",
    "\n",
    "    why_acc = []\n",
    "    why_notes = []\n",
    "    for _, r in df.iterrows():\n",
    "        accs = accords_set_from_row(r)\n",
    "        why_acc.append(', '.join(sorted(accs & query_accords)))\n",
    "        if bridge is not None:\n",
    "            notes = get_item_notes(str(r['fragrance_id']),bridge,k_per_level=3)\n",
    "            why_notes.append(f\"top: {', '.join(notes.get('top',[]))} | mid: {', '.join(notes.get('mid',[]))} | base: {', '.join(notes.get('base',[]))}\")\n",
    "        else:\n",
    "            why_notes.append(\"\")\n",
    "    df['why_accords_overlap'] = why_acc\n",
    "    df['sample_notes'] = why_notes\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ],
   "id": "183c9fe66d01e540",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sanity Check",
   "id": "6e04f2340ce97cb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:05:51.909840Z",
     "start_time": "2025-09-12T03:04:16.980661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Minimal preference (accords only)\n",
    "test_pref = {\n",
    "    \"liked_accords_ranked\": [\n",
    "        {\"name\": \"woody\", \"rank\": 1},\n",
    "        {\"name\": \"citrus\", \"rank\": 2},\n",
    "        {\"name\": \"aromatic\", \"rank\": 3},\n",
    "        {\"name\": \"fresh spicy\", \"rank\": 4},\n",
    "        {\"name\": \"vanilla\", \"rank\": 5},\n",
    "    ],\n",
    "    \"gender_focus\": \"any\",\n",
    "    \"season\": \"summer\",\n",
    "    \"use_case\": \"office\",\n",
    "    \"intensity\": \"moderate\",\n",
    "}\n",
    "\n",
    "out_ae = recommend(test_pref, mode=\"ae\", top_k=CFG['topk'])\n",
    "out_svd = recommend(test_pref, mode=\"svd\", top_k=CFG['topk'])\n",
    "\n",
    "out_ae = attach_llm_explanations(out_ae,test_pref, model='gpt-4o-mini')\n",
    "out_svd = attach_llm_explanations(out_svd,test_pref, model='gpt-4o-mini')\n",
    "\n",
    "display(out_ae.head(5)[[\"Brand\",\"Perfume\",\"Year\",\"why_accords_overlap\",\"sample_notes\",\"explanation_llm\"]])\n",
    "display(out_svd.head(5)[[\"Brand\",\"Perfume\",\"Year\",\"why_accords_overlap\",\"sample_notes\",\"explanation_llm\"]])\n",
    "\n",
    "assert out_ae.shape[0] > 0 and out_svd.shape[0] > 0, \"Empty results — check query build or filters.\""
   ],
   "id": "61ab8b5c0cf0d794",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Brand                                            Perfume    Year  \\\n",
       "0        benetton                                 benetton-sport-man  2001.0   \n",
       "1          azzaro                               chrome-eau-de-parfum  2022.0   \n",
       "2    issey-miyake  l-eau-d-issey-pour-homme-summer-edition-by-kev...  2022.0   \n",
       "3  acqua-di-parma                                 note-di-colonia-ii  2016.0   \n",
       "4          vertus                                       bois-et-cuir  2015.0   \n",
       "\n",
       "                    why_accords_overlap  \\\n",
       "0  aromatic, citrus, fresh spicy, woody   \n",
       "1               aromatic, citrus, woody   \n",
       "2          aromatic, fresh spicy, woody   \n",
       "3  aromatic, citrus, fresh spicy, woody   \n",
       "4  aromatic, citrus, fresh spicy, woody   \n",
       "\n",
       "                                        sample_notes  \\\n",
       "0  top: lime, lemon, clementine | mid: ginger flo...   \n",
       "1   top: green mandarin | mid: lavender | base: pine   \n",
       "2  top: watery notes, bergamot, lemon | mid: euca...   \n",
       "3  top: basil, bergamot, orange | mid: sandalwood...   \n",
       "4  top: grapefruit, ivy, apple | mid: cedar, lave...   \n",
       "\n",
       "                                     explanation_llm  \n",
       "0  This captures the essence of summer vitality, ...  \n",
       "1  This captures the essence of summer in the off...  \n",
       "2  This captures the essence of summer in the off...  \n",
       "3  This captures the essence of summer in an offi...  \n",
       "4  This captures the essence of summer in the off...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Perfume</th>\n",
       "      <th>Year</th>\n",
       "      <th>why_accords_overlap</th>\n",
       "      <th>sample_notes</th>\n",
       "      <th>explanation_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benetton</td>\n",
       "      <td>benetton-sport-man</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>aromatic, citrus, fresh spicy, woody</td>\n",
       "      <td>top: lime, lemon, clementine | mid: ginger flo...</td>\n",
       "      <td>This captures the essence of summer vitality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>azzaro</td>\n",
       "      <td>chrome-eau-de-parfum</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>aromatic, citrus, woody</td>\n",
       "      <td>top: green mandarin | mid: lavender | base: pine</td>\n",
       "      <td>This captures the essence of summer in the off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issey-miyake</td>\n",
       "      <td>l-eau-d-issey-pour-homme-summer-edition-by-kev...</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>aromatic, fresh spicy, woody</td>\n",
       "      <td>top: watery notes, bergamot, lemon | mid: euca...</td>\n",
       "      <td>This captures the essence of summer in the off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acqua-di-parma</td>\n",
       "      <td>note-di-colonia-ii</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>aromatic, citrus, fresh spicy, woody</td>\n",
       "      <td>top: basil, bergamot, orange | mid: sandalwood...</td>\n",
       "      <td>This captures the essence of summer in an offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vertus</td>\n",
       "      <td>bois-et-cuir</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>aromatic, citrus, fresh spicy, woody</td>\n",
       "      <td>top: grapefruit, ivy, apple | mid: cedar, lave...</td>\n",
       "      <td>This captures the essence of summer in the off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "               Brand                Perfume    Year  \\\n",
       "0        alain-delon            samourai-47  2002.0   \n",
       "1           ds-durga  grapefruit-generation  2021.0   \n",
       "2  comme-des-garcons       scent-three-sugi  2013.0   \n",
       "3             fossil  fossil-1954-for-women  2014.0   \n",
       "4               avon       instinct-for-him  2013.0   \n",
       "\n",
       "            why_accords_overlap  \\\n",
       "0       aromatic, citrus, woody   \n",
       "1    citrus, fresh spicy, woody   \n",
       "2  aromatic, fresh spicy, woody   \n",
       "3       aromatic, citrus, woody   \n",
       "4       aromatic, citrus, woody   \n",
       "\n",
       "                                        sample_notes  \\\n",
       "0  top: japanese plum, tarragon, lemon | mid: lav...   \n",
       "1  top: pomelo, elm | mid: paradisone, hawthorn, ...   \n",
       "2  top: cypress, madagascar pepper | mid: iris, v...   \n",
       "3  top: ginger, grapefruit, mandarin blossom | mi...   \n",
       "4     top: mandarin orange | mid: sage | base: ebony   \n",
       "\n",
       "                                     explanation_llm  \n",
       "0  This captures the essence of summer in an offi...  \n",
       "1  This captures the essence of summer vitality, ...  \n",
       "2  This captures the essence of a refreshing summ...  \n",
       "3  This captures the essence of summer in the off...  \n",
       "4  This captures the essence of a refreshing summ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Perfume</th>\n",
       "      <th>Year</th>\n",
       "      <th>why_accords_overlap</th>\n",
       "      <th>sample_notes</th>\n",
       "      <th>explanation_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alain-delon</td>\n",
       "      <td>samourai-47</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>aromatic, citrus, woody</td>\n",
       "      <td>top: japanese plum, tarragon, lemon | mid: lav...</td>\n",
       "      <td>This captures the essence of summer in an offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ds-durga</td>\n",
       "      <td>grapefruit-generation</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>citrus, fresh spicy, woody</td>\n",
       "      <td>top: pomelo, elm | mid: paradisone, hawthorn, ...</td>\n",
       "      <td>This captures the essence of summer vitality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comme-des-garcons</td>\n",
       "      <td>scent-three-sugi</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>aromatic, fresh spicy, woody</td>\n",
       "      <td>top: cypress, madagascar pepper | mid: iris, v...</td>\n",
       "      <td>This captures the essence of a refreshing summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fossil</td>\n",
       "      <td>fossil-1954-for-women</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>aromatic, citrus, woody</td>\n",
       "      <td>top: ginger, grapefruit, mandarin blossom | mi...</td>\n",
       "      <td>This captures the essence of summer in the off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avon</td>\n",
       "      <td>instinct-for-him</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>aromatic, citrus, woody</td>\n",
       "      <td>top: mandarin orange | mid: sage | base: ebony</td>\n",
       "      <td>This captures the essence of a refreshing summ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:05:52.048461Z",
     "start_time": "2025-09-12T03:05:52.044629Z"
    }
   },
   "cell_type": "code",
   "source": "out_ae.head(2)[['explanation_llm']]",
   "id": "41685470dac4b637",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     explanation_llm\n",
       "0  This captures the essence of summer vitality, ...\n",
       "1  This captures the essence of summer in the off..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This captures the essence of summer vitality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This captures the essence of summer in the off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"This captures the essence of summer vitality, making it a refreshing companion for the office.\\n\\n- The zesty citrus notes of lime and lemon invigorate your senses, creating an uplifting atmosphere.\\n- Aromatic hints of ginger flower and geranium add a sophisticated twist, ensuring you stand out in a professional setting.\\n- The woody base of cedar and sandalwood grounds the fragrance, lending a subtle warmth that resonates throughout the day.\"\n",
    "\n",
    "\"This captures the essence of summer in the office with its invigorating freshness.  \\n- The watery notes and citrusy bergamot create an uplifting atmosphere, energizing your workday.  \\n- Eucalyptus and basil in the heart add a refreshing twist, making every interaction feel vibrant.  \\n- The woody base of cypress and pine grounds the fragrance, ensuring it remains sophisticated and professional.\"\n"
   ],
   "id": "557d31f16278b22c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation Metrics",
   "id": "2dc47b64d87c2163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Precision@k:** Fraction of recommended items in the top-k that are relevant.\n",
    "- **nDCG:** Captures ranking quality; relevant items at rank 1 count more than at rank 10.\n",
    "- **Intra-List Diversity (ILD):** 1- average pairwise cosine among results -> higher is better variety.\n",
    "- **Novelty:**  penalize super-popular items (log Rating Count proxy).\n",
    "- **Persona Alignment:** do the results reflect a user's high-level taste (accords)?"
   ],
   "id": "4de31229cd2a1cc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:05:52.088687Z",
     "start_time": "2025-09-12T03:05:52.083367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rank\n",
    "def precision_at_k(rels: np.ndarray, k: int) -> float:\n",
    "    k = min(k, len(rels))\n",
    "    return 0.0 if k == 0 else float(rels[:k].sum()) / float(k)\n",
    "\n",
    "def dcg_at_k(gains: np.ndarray, k: int) -> float:\n",
    "    k = min(k, len(gains))\n",
    "    if k == 0: return 0.0\n",
    "    denom = np.log2(np.arange(2, k+2))\n",
    "    return float((gains[:k] / denom).sum())\n",
    "\n",
    "def ndcg_at_k(gains: np.ndarray, k: int) -> float:\n",
    "    k = min(k, len(gains))\n",
    "    if k == 0: return 0.0\n",
    "    ideal = np.sort(gains)[::-1]\n",
    "    idcg  = dcg_at_k(ideal, k)\n",
    "    return 0.0 if idcg == 0.0 else float(dcg_at_k(gains, k) / idcg)\n",
    "\n",
    "# Diversity\n",
    "def intra_list_diversity(ids: list, Z_catalog: np.ndarray) -> float:\n",
    "    \"\"\"ILD = 1 − mean cosine similarity among results (higher → more variety).\"\"\"\n",
    "    if len(ids) <= 1: return 0.0\n",
    "    M = Z_catalog[ids]  # (m×d)\n",
    "    S = cosine_similarity(M)\n",
    "    tri = S[np.triu_indices(len(ids), k=1)]\n",
    "    return float(1.0 - tri.mean()) if tri.size else 0.0\n",
    "\n",
    "# Novelty\n",
    "def avg_novelty_log_pop(recs_df, eps: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    Novelty via -log(popularity), with popularity proxied by Rating Count.\n",
    "    Higher = more novel (less globally popular).\n",
    "    \"\"\"\n",
    "    if recs_df is None or recs_df.empty: return 0.0\n",
    "    pop = recs_df[\"Rating Count\"].to_numpy(dtype=float)\n",
    "    return float((-np.log(pop + eps)).mean())\n",
    "\n",
    "# Persona Alignement with accords per recommendation\n",
    "def persona_alignment_jaccard(recs_df: pd.DataFrame, persona: dict) -> float:\n",
    "    \"\"\"\n",
    "    Mean Jaccard similarity between persona's liked accords (names only)\n",
    "    and each item's {mainaccord1..5}. Higher = better alignment with high-level taste.\n",
    "    \"\"\"\n",
    "    ranked = persona.get('liked_accords_ranked', [])\n",
    "    P = {\n",
    "        str(e.get('name', '')).strip().lower()\n",
    "        for e in ranked if isinstance(e, dict) and str(e.get('name', '')).strip()\n",
    "    }\n",
    "    if not P or recs_df is None or recs_df.empty:\n",
    "        return 0.0\n",
    "\n",
    "    sims = []\n",
    "    for _, r in recs_df.iterrows():\n",
    "        A = {\n",
    "            str(r.get(f\"mainaccord{j}\", \"\")).strip().lower()\n",
    "            for j in range(1, 6)\n",
    "            if isinstance(r.get(f\"mainaccord{j}\"), str) and str(r.get(f\"mainaccord{j}\", \"\")).strip()\n",
    "        }\n",
    "        inter = len(P & A)\n",
    "        union = max(1, len(P | A))\n",
    "        sims.append(inter / union)\n",
    "    return float(np.mean(sims)) if sims else 0.0"
   ],
   "id": "52e447cc4e9ee8f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These are helpers for getting the relevance score of a persona against each item in the recommendations.",
   "id": "983fdaa7e701a738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:05:53.231548Z",
     "start_time": "2025-09-12T03:05:52.127136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_note_index(bridge_df: pd.DataFrame) -> dict:\n",
    "    if bridge_df is None or bridge_df.empty: return {}\n",
    "    g = bridge_df.groupby('fragrance_id')['note'].apply(lambda s: set(map(str.lower, s.astype(str))))\n",
    "    return {str(k): set(v) for k,v in g.items()}\n",
    "\n",
    "NOTE_INDEX = build_note_index(bridge)\n",
    "\n",
    "def item_accord_weight(row: pd.Series) -> dict:\n",
    "    d = {}\n",
    "    for pos, w in enumerate(ACCORD_POS_WEIGHTS, start=1):  # 1..5\n",
    "        a = row.get(f\"mainaccord{pos}\", \"\")\n",
    "        if isinstance(a, str) and a.strip():\n",
    "            d[a.strip().lower()] = float(w)\n",
    "    return d\n",
    "\n",
    "ITEM_ACCORD_WEIGHTS = [item_accord_weight(items.iloc[i]) for i in range(len(items))]\n",
    "\n",
    "# Penalties (tunable, mirroring block magnitudes)\n",
    "LAMBDA_ACC_PENALTY  = 0.80   # disliked accords\n",
    "LAMBDA_NOTE_PENALTY = 0.35   # avoid notes\n",
    "\n",
    "def persona_item_score(persona: dict, row_idx: int) -> float:\n",
    "    \"\"\"\n",
    "    Continuous relevance s(i|persona): accord gains + note gains - penalties.\n",
    "    Matches weighting: accords use rank weights; notes use W_NOTE per level.\n",
    "    \"\"\"\n",
    "    pw = {}\n",
    "    for e in persona.get('liked_accords_ranked',[]):\n",
    "        name = str(e.get('name','')).strip().lower()\n",
    "        rank = int(e.get('rank',0))\n",
    "        if (1<= rank <=5) and name:\n",
    "            pw[name] = float(ACCORD_POS_WEIGHTS[rank-1])\n",
    "    liked_top = set(map(str.lower, persona.get(\"liked_notes_top\", [])))\n",
    "    liked_mid = set(map(str.lower, persona.get(\"liked_notes_mid\", [])))\n",
    "    liked_base = set(map(str.lower, persona.get(\"liked_notes_base\", [])))\n",
    "    avoid_notes = set(map(str.lower, persona.get(\"avoid_notes\", [])))\n",
    "    disliked_accs = set(map(str.lower, persona.get(\"disliked_accords\", [])))\n",
    "\n",
    "    fid = str(items.iloc[row_idx]['fragrance_id'])\n",
    "    notes_i = NOTE_INDEX.get(fid, set())\n",
    "    acc_i_w = ITEM_ACCORD_WEIGHTS[row_idx]\n",
    "\n",
    "    # Accord gain\n",
    "    acc_gain = 0.0\n",
    "    for a, w_p in pw.items():\n",
    "        w_i = acc_i_w.get(a, 0.0)\n",
    "        if w_i > 0:\n",
    "            acc_gain += w_p * w_i\n",
    "\n",
    "    # Note gain\n",
    "    note_gain = (\n",
    "        W_NOTE[\"top\"]  * len(liked_top  & notes_i) +\n",
    "        W_NOTE[\"mid\"]  * len(liked_mid  & notes_i) +\n",
    "        W_NOTE[\"base\"] * len(liked_base & notes_i)\n",
    "    )\n",
    "\n",
    "    # Penalties for explicit dislikes/avoids\n",
    "    acc_pen = LAMBDA_ACC_PENALTY  * len(disliked_accs & set(acc_i_w.keys()))\n",
    "    note_pen= LAMBDA_NOTE_PENALTY * len(avoid_notes  & notes_i)\n",
    "\n",
    "    return float(acc_gain + note_gain - acc_pen - note_pen)\n",
    "\n",
    "def persona_catalog_scores(persona: dict, gain_cap: float = 6.0, thresh: float = 0.0):\n",
    "    \"\"\"\n",
    "    Returns arrays aligned to `items` rows:\n",
    "      - scores_all  : continuous s(i|persona)\n",
    "      - binary_all  : 1 if s > thresh (for precision/recall)\n",
    "      - gains_all   : max(0, s) clipped to gain_cap (for nDCG idealization)\n",
    "    \"\"\"\n",
    "    N = len(items)\n",
    "    scores = np.fromiter((persona_item_score(persona,i) for i in range(N)), dtype=float, count=N)\n",
    "    binary = (scores > float(thresh)).astype(np.float32)\n",
    "    gains = np.maximum(scores, 0.0)\n",
    "    if gain_cap is not None:\n",
    "        gains = np.minimum(gains, float(gain_cap))\n",
    "    return scores, binary, gains"
   ],
   "id": "9f272b69c88cd3ea",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluate functions",
   "id": "ec00186b29c0b299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:05:53.303049Z",
     "start_time": "2025-09-12T03:05:53.297359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_recommender(\n",
    "    personas_input,                  # dict (single persona) OR pd.DataFrame (many)\n",
    "    mode: str = \"ae\",\n",
    "    k: int = CFG[\"eval_k\"],\n",
    "    sample_n: int = None,           # only used if personas_input is a DataFrame\n",
    "    seed: int = 42,\n",
    "    gain_cap: float = 6.0,\n",
    "    thresh: float = 0.0,\n",
    "    recs_df: pd.DataFrame = None,\n",
    "    recs_map: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      personas_input : dict OR pd.DataFrame\n",
    "          - dict: a single persona in the schema used by `recommend()`\n",
    "          - DataFrame: many personas\n",
    "      mode           : \"ae\" or \"svd\"\n",
    "      k              : top-k to evaluate\n",
    "      sample_n       : subsample personas when DataFrame is passed\n",
    "      gain_cap       : cap for graded gain used in nDCG\n",
    "      thresh         : threshold for binary relevance (precision/recall)\n",
    "      recs_df        : precomputed recs DF for the single-persona case\n",
    "      recs_map       : dict of {persona_idx: recs DF} for the multi-persona case\n",
    "\n",
    "    Returns:\n",
    "      summary_dict, details_df\n",
    "    \"\"\"\n",
    "    if isinstance(personas_input, dict):\n",
    "        personas_iter = [personas_input]\n",
    "        persona_indices = [0]\n",
    "        # Single persona: allow a single precomputed recs_df\n",
    "        precomputed_for_idx = {0: recs_df} if recs_df is not None else {}\n",
    "    elif isinstance(personas_input, pd.DataFrame):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idxs = personas_input.index.to_list()\n",
    "        if sample_n and sample_n < len(idxs):\n",
    "            idxs = list(rng.choice(idxs, size=sample_n, replace=False))\n",
    "        personas_iter = [personas_input.loc[i].to_dict() for i in idxs]\n",
    "        persona_indices = idxs\n",
    "        precomputed_for_idx = recs_map or {}\n",
    "    else:\n",
    "        raise TypeError('personas_input must be a dict or pd.DataFrame')\n",
    "    # Choose Catalog embedding space for ILD\n",
    "    Z_catalog = Z_ae if mode == 'ae' else Z_svd\n",
    "\n",
    "    rows, all_ids = [], []\n",
    "    for i, persona in zip(persona_indices, personas_iter):\n",
    "        # Persona to catalog relevance (for P/R/nDCG ground-truth)\n",
    "        scores_all, binary_all, gains_all = persona_catalog_scores(\n",
    "            persona, gain_cap=gain_cap, thresh=thresh\n",
    "        )\n",
    "        gt_count = int(binary_all.sum())\n",
    "\n",
    "        # use precomputer recs if provided, otherwise compute using recommend function\n",
    "        recs = precomputed_for_idx.get(i, None)\n",
    "        if recs is None:\n",
    "            recs = recommend(persona, mode=mode, top_k=k)\n",
    "        # keep only top-k rows if a larger DF was supplied\n",
    "        if recs is not None and not recs.empty and len(recs) > k:\n",
    "            recs = recs.iloc[:k].copy()\n",
    "\n",
    "        if recs is None or recs.empty:\n",
    "            rows.append({\n",
    "                \"persona_idx\": i, \"returned\": 0, \"gt_relevant\": gt_count,\n",
    "                \"precision\": 0.0, \"nDCG\": 0.0,\n",
    "                \"ILD\": 0.0, \"Novelty\": 0.0, \"PersonaAlign\": 0.0\n",
    "            })\n",
    "            all_ids.append([])\n",
    "            continue\n",
    "\n",
    "        # Align recs to catalog row indices\n",
    "        rec_row_idx = recs.index.to_list()\n",
    "        all_ids.append(rec_row_idx)\n",
    "\n",
    "        #Ranked relevance vectors (from persona scores)\n",
    "        binary_ranked = (scores_all[rec_row_idx] > thresh).astype(float)\n",
    "        gains_ranked = np.minimum(np.maximum(scores_all[rec_row_idx], 0.0), gain_cap)\n",
    "\n",
    "        # Metrics\n",
    "        prec = precision_at_k(binary_ranked, k)\n",
    "        ideal = np.sort(gains_all)[::-1]\n",
    "        idcg = dcg_at_k(ideal,k)\n",
    "        ndcg = (dcg_at_k(gains_ranked, k) / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "        ild = intra_list_diversity(rec_row_idx, Z_catalog)\n",
    "        nov = avg_novelty_log_pop(recs)\n",
    "        pal = persona_alignment_jaccard(recs,persona)\n",
    "\n",
    "        rows.append({\n",
    "            \"persona_idx\": i,\n",
    "            \"returned\": len(recs), \"gt_relevant\": gt_count,\n",
    "            \"precision\": prec, \"nDCG\": ndcg,\n",
    "            \"ILD\": ild, \"Novelty\": nov, \"PersonaAlign\": pal\n",
    "        })\n",
    "\n",
    "    #Aggregate\n",
    "    details = pd.DataFrame(rows)\n",
    "    summary = {\n",
    "        \"mode\": mode, \"k\": k, \"n_personas\": len(details),\n",
    "        \"Precision@k_mean\": float(details[\"precision\"].mean()) if len(details) else 0.0,\n",
    "        \"nDCG@k_mean\":      float(details[\"nDCG\"].mean())      if len(details) else 0.0,\n",
    "        \"ILD_mean\":         float(details[\"ILD\"].mean())        if len(details) else 0.0,\n",
    "        \"Novelty_mean\":     float(details[\"Novelty\"].mean())    if len(details) else 0.0,\n",
    "        \"PersonaAlign_mean\":float(details[\"PersonaAlign\"].mean()) if len(details) else 0.0,\n",
    "    }\n",
    "    return summary, details"
   ],
   "id": "3e067891fc7ba158",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### A/B Testing using personas",
   "id": "889570e5b42edffa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:06:26.366545Z",
     "start_time": "2025-09-12T03:05:53.309925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "personas_ae = personas[:50].reset_index(drop=True)\n",
    "personas_svd = personas[50:].reset_index(drop=True)\n",
    "summary_ae, details_ae = evaluate_recommender(personas_ae, mode=\"ae\", k=CFG['eval_k'], sample_n=20, seed=42)\n",
    "summary_svd, details_svd = evaluate_recommender(personas_svd, mode=\"svd\", k=CFG['eval_k'], sample_n=20, seed=42)\n",
    "\n",
    "display(summary_ae, details_ae)\n",
    "display(summary_svd, details_svd)"
   ],
   "id": "963e07c0be0289e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mode': 'ae',\n",
       " 'k': 20,\n",
       " 'n_personas': 20,\n",
       " 'Precision@k_mean': 0.7799999999999999,\n",
       " 'nDCG@k_mean': 0.1710616278250811,\n",
       " 'ILD_mean': 0.6599939465522766,\n",
       " 'Novelty_mean': -5.067697349080225,\n",
       " 'PersonaAlign_mean': 0.3928194444444444}"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "    persona_idx  returned  gt_relevant  precision      nDCG       ILD  \\\n",
       "0            24        20        19067       1.00  0.147584  0.659994   \n",
       "1            32        20        20661       0.85  0.190617  0.659994   \n",
       "2             7        20        18539       1.00  0.156103  0.659994   \n",
       "3            41        20        22979       0.85  0.214093  0.659994   \n",
       "4            48        20        17661       0.85  0.168787  0.659994   \n",
       "5            33        20        19312       0.55  0.139539  0.659994   \n",
       "6             6        20        18975       0.60  0.149171  0.659994   \n",
       "7             2        20        17204       0.55  0.145305  0.659994   \n",
       "8            21        20        18975       0.60  0.149171  0.659994   \n",
       "9            46        20        16179       0.70  0.177933  0.659994   \n",
       "10           15        20        19062       0.90  0.172065  0.659994   \n",
       "11            3        20        20589       0.75  0.208930  0.659994   \n",
       "12           22        20        17204       0.55  0.145305  0.659994   \n",
       "13           30        20        18722       0.95  0.158624  0.659994   \n",
       "14           39        20        19312       0.55  0.139539  0.659994   \n",
       "15           31        20        21015       0.70  0.170463  0.659994   \n",
       "16           36        20        23026       0.95  0.215745  0.659994   \n",
       "17           14        20        20589       0.75  0.208930  0.659994   \n",
       "18           26        20        23026       0.95  0.215745  0.659994   \n",
       "19           40        20        19067       1.00  0.147584  0.659994   \n",
       "\n",
       "     Novelty  PersonaAlign  \n",
       "0  -5.065103      0.339286  \n",
       "1  -5.313338      0.347778  \n",
       "2  -4.971043      0.378968  \n",
       "3  -4.959819      0.470794  \n",
       "4  -5.107889      0.390079  \n",
       "5  -4.674151      0.309524  \n",
       "6  -5.764262      0.404405  \n",
       "7  -4.859031      0.415675  \n",
       "8  -5.764262      0.404405  \n",
       "9  -5.208414      0.364484  \n",
       "10 -5.336139      0.346032  \n",
       "11 -5.121531      0.502381  \n",
       "12 -4.859031      0.415675  \n",
       "13 -4.799086      0.376587  \n",
       "14 -4.674151      0.309524  \n",
       "15 -4.764770      0.257937  \n",
       "16 -4.962646      0.490595  \n",
       "17 -5.121531      0.502381  \n",
       "18 -4.962646      0.490595  \n",
       "19 -5.065103      0.339286  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona_idx</th>\n",
       "      <th>returned</th>\n",
       "      <th>gt_relevant</th>\n",
       "      <th>precision</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>ILD</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>PersonaAlign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>19067</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.065103</td>\n",
       "      <td>0.339286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>20661</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.190617</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.313338</td>\n",
       "      <td>0.347778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>18539</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.156103</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.971043</td>\n",
       "      <td>0.378968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>22979</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.214093</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.959819</td>\n",
       "      <td>0.470794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>17661</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.168787</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.107889</td>\n",
       "      <td>0.390079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>19312</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.139539</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.674151</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>18975</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.149171</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.764262</td>\n",
       "      <td>0.404405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>17204</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.145305</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.859031</td>\n",
       "      <td>0.415675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>18975</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.149171</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.764262</td>\n",
       "      <td>0.404405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>16179</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.177933</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.208414</td>\n",
       "      <td>0.364484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>19062</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.172065</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.336139</td>\n",
       "      <td>0.346032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20589</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.121531</td>\n",
       "      <td>0.502381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>17204</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.145305</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.859031</td>\n",
       "      <td>0.415675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>18722</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.158624</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.799086</td>\n",
       "      <td>0.376587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>19312</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.139539</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.674151</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>21015</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.170463</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.764770</td>\n",
       "      <td>0.257937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>23026</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.215745</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.962646</td>\n",
       "      <td>0.490595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20589</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.208930</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.121531</td>\n",
       "      <td>0.502381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>23026</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.215745</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-4.962646</td>\n",
       "      <td>0.490595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>19067</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>0.659994</td>\n",
       "      <td>-5.065103</td>\n",
       "      <td>0.339286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "{'mode': 'svd',\n",
       " 'k': 20,\n",
       " 'n_personas': 20,\n",
       " 'Precision@k_mean': 0.7575000000000001,\n",
       " 'nDCG@k_mean': 0.18201216094934677,\n",
       " 'ILD_mean': 0.8594247229515221,\n",
       " 'Novelty_mean': -5.1630123895791,\n",
       " 'PersonaAlign_mean': 0.4322123015873016}"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "    persona_idx  returned  gt_relevant  precision      nDCG       ILD  \\\n",
       "0            18        20        20705       0.65  0.185071  0.859425   \n",
       "1            36        20        17014       0.80  0.154744  0.859425   \n",
       "2             6        20        16179       0.70  0.177933  0.859425   \n",
       "3            33        20        19921       0.65  0.187527  0.859425   \n",
       "4            34        20        19037       0.80  0.211152  0.859425   \n",
       "5            27        20        19670       0.65  0.161399  0.859425   \n",
       "6             5        20        23339       0.95  0.208932  0.859425   \n",
       "7             2        20        18959       0.55  0.123572  0.859425   \n",
       "8            16        20        17658       0.85  0.170144  0.859425   \n",
       "9            38        20        19037       0.80  0.211152  0.859425   \n",
       "10           26        20        19037       0.80  0.211152  0.859425   \n",
       "11           28        20        17014       0.80  0.154744  0.859425   \n",
       "12           41        20        19921       0.65  0.187527  0.859425   \n",
       "13           24        20        17014       0.80  0.154744  0.859425   \n",
       "14            3        20        16179       0.70  0.177933  0.859425   \n",
       "15           25        20        19921       0.65  0.187527  0.859425   \n",
       "16           29        20        19921       0.65  0.187527  0.859425   \n",
       "17           11        20        23339       0.95  0.208932  0.859425   \n",
       "18           20        20        17088       0.75  0.144692  0.859425   \n",
       "19           17        20        19769       1.00  0.233839  0.859425   \n",
       "\n",
       "     Novelty  PersonaAlign  \n",
       "0  -4.935901      0.515119  \n",
       "1  -5.134513      0.503214  \n",
       "2  -5.248640      0.440079  \n",
       "3  -5.371157      0.335317  \n",
       "4  -4.856849      0.422619  \n",
       "5  -4.993696      0.425595  \n",
       "6  -5.025529      0.448413  \n",
       "7  -5.282807      0.397460  \n",
       "8  -5.187578      0.466667  \n",
       "9  -4.856849      0.422619  \n",
       "10 -4.856849      0.422619  \n",
       "11 -5.134513      0.503214  \n",
       "12 -5.371157      0.335317  \n",
       "13 -5.134513      0.503214  \n",
       "14 -5.248640      0.440079  \n",
       "15 -5.371157      0.335317  \n",
       "16 -5.371157      0.335317  \n",
       "17 -5.025529      0.448413  \n",
       "18 -5.525413      0.466865  \n",
       "19 -5.327801      0.476786  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona_idx</th>\n",
       "      <th>returned</th>\n",
       "      <th>gt_relevant</th>\n",
       "      <th>precision</th>\n",
       "      <th>nDCG</th>\n",
       "      <th>ILD</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>PersonaAlign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20705</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-4.935901</td>\n",
       "      <td>0.515119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>17014</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.154744</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.134513</td>\n",
       "      <td>0.503214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>16179</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.177933</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.248640</td>\n",
       "      <td>0.440079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>19921</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.187527</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.371157</td>\n",
       "      <td>0.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>19037</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.211152</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-4.856849</td>\n",
       "      <td>0.422619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>19670</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.161399</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-4.993696</td>\n",
       "      <td>0.425595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>23339</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.208932</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.025529</td>\n",
       "      <td>0.448413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>18959</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.282807</td>\n",
       "      <td>0.397460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>17658</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.170144</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.187578</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>19037</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.211152</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-4.856849</td>\n",
       "      <td>0.422619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>19037</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.211152</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-4.856849</td>\n",
       "      <td>0.422619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>17014</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.154744</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.134513</td>\n",
       "      <td>0.503214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>19921</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.187527</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.371157</td>\n",
       "      <td>0.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>17014</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.154744</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.134513</td>\n",
       "      <td>0.503214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>16179</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.177933</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.248640</td>\n",
       "      <td>0.440079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>19921</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.187527</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.371157</td>\n",
       "      <td>0.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>19921</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.187527</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.371157</td>\n",
       "      <td>0.335317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>23339</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.208932</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.025529</td>\n",
       "      <td>0.448413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>17088</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.144692</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.525413</td>\n",
       "      <td>0.466865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19769</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.233839</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>-5.327801</td>\n",
       "      <td>0.476786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation Results (k = 20, n_personas = 20)\n",
    "\n",
    "### Autoencoder (AE)\n",
    "- **Precision@20:** **0.78**, strong; AE retrieves slightly more relevant items than SVD.\n",
    "- **nDCG@20:** **0.171**, moderate ranking quality; relevant items are included but not always prioritized.\n",
    "- **ILD:** **0.66**, fair diversity, but significantly lower than SVD.\n",
    "- **Novelty:** **-5.07** → moderate novelty; slightly better than SVD (less skewed toward popularity).\n",
    "- **Persona Alignment:** **0.39** → weaker alignment compared to SVD → **could improve by giving more weight to persona preferences during query building or persona boosting**.\n",
    "\n",
    "### Truncated SVD\n",
    "- **Precision@20:** **0.76**, slightly lower than AE, but still strong.\n",
    "- **nDCG@20:** **0.182**, higher than AE; better ranking of relevant items.\n",
    "- **ILD:** **0.86**, excellent diversity, much higher than AE → strong exploration benefit.\n",
    "- **Novelty:** **-5.16**, a bit lower (worse) than AE, indicating heavier reliance on popular items\n",
    "- **Persona Alignment:** **0.43**, better than AE, showing stronger reflection of user taste.\n",
    "\n",
    "### Takeaways & Improvements\n",
    "- **AE**: Best at raw relevance (precision) and slightly better novelty, but weaker at diversity and persona alignment.\n",
    "   *Improvements*: tune **MMR λ** to favor more diversity, strengthen **persona boost** to align better with stated tastes.\n",
    "\n",
    "- **SVD**: Best at ranking quality (nDCG), diversity (ILD), and persona alignment, but weaker at precision and novelty.\n",
    "  *Improvements*: add **novelty-aware re-ranking** (e.g., penalize popular fragrances), and rebalance towards precision by slightly increasing **relevance weight** in MMR.\n",
    "\n",
    "- **Overall**:\n",
    "  - AE is safer for users wanting highly relevant & slightly less mainstream picks.\n",
    "  - SVD is better for variety and taste alignment but risks over-recommending popular items."
   ],
   "id": "16eb776265678d1b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save Manifest",
   "id": "7d50f684ec0054d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T03:06:26.539958Z",
     "start_time": "2025-09-12T03:06:26.513577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manifest = {\n",
    "    \"feature_meta_hash\": hash(json.dumps(feature_meta, sort_keys=True)),\n",
    "    \"X_shape\": list(X.shape),\n",
    "    \"Z_ae_shape\": list(Z_ae.shape),\n",
    "    \"Z_svd_shape\": list(Z_svd.shape),\n",
    "    \"ZP_ae_shape\": list(ZP_ae.shape),\n",
    "    \"ZP_svd_shape\": list(ZP_svd.shape),\n",
    "    \"A_item_persona_ae_shape\": list(A_item_persona_ae.shape),\n",
    "    \"A_item_persona_svd_shape\": list(A_item_persona_svd.shape),\n",
    "    \"cfg\": CFG,\n",
    "}\n",
    "(ART / 'model_manifest.json').write_text(json.dumps(manifest, indent=2))"
   ],
   "id": "25c86ee2355594ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "\n",
    "[The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries. Jamie Carbonell, and Jade Goldstein.](https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf)\n",
    "\n",
    "[Masked Autoencoders: A Simple Yet Powerful Approach to Self-Supervised Vision Learning](https://medium.com/@jimcanary/masked-autoencoders-a-simple-yet-powerful-approach-to-self-supervised-vision-learning-0ec9dc849dd2)"
   ],
   "id": "d3ddf42dcdf98055"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
